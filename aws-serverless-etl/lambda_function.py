# -*- coding: utf-8 -*-
"""lambda_function.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b23dziaBV8qQMlaJDAy6ImFTvVYIzpFr
"""

import json
import boto3
import pandas as pd
import io

# CONFIGURATION
# Replace the string below with the EXACT name of your clean bucket
TARGET_BUCKET = "cleaned-data-bucket-ayan"

def lambda_handler(event, context):
    s3_client = boto3.client('s3')

    # 1. Get the bucket name and file name from the event that triggered the Lambda
    source_bucket = event['Records'][0]['s3']['bucket']['name']
    file_key = event['Records'][0]['s3']['object']['key']

    print(f"Detected file: {file_key} in bucket: {source_bucket}")

    try:
        # 2. Download the file from S3 into memory
        response = s3_client.get_object(Bucket=source_bucket, Key=file_key)
        file_content = response['Body'].read()

        # 3. Read data into Pandas
        df = pd.read_csv(io.BytesIO(file_content), skipinitialspace=True)

        print("Data loaded into Pandas successfully.")

        # DATA CLEANING LOGIC START

        # A. Convert cells that are just whitespace to NaN (Null)

        import numpy as np
        df = df.replace(r'^\s*$', np.nan, regex=True)

        # B. Remove rows where critical data is missing
        df.dropna(inplace=True)

        # C. Standardize column names (remove spaces, make lowercase)
        df.columns = df.columns.str.strip().str.lower()

        # D. Add a "Processed" tag
        df['processed_by'] = 'AWS_Lambda'

        # --- DATA CLEANING LOGIC END ---

        print("Data cleaning complete.")

        # 4. Convert dataframe back to CSV in memory
        clean_buffer = io.StringIO()
        df.to_csv(clean_buffer, index=False)

        # 5. Define the new file name
        clean_key = "clean_" + file_key.split('/')[-1]

        # 6. Upload to the Clean Bucket
        s3_client.put_object(
            Bucket=TARGET_BUCKET,
            Key=clean_key,
            Body=clean_buffer.getvalue()
        )

        print(f"Success! Clean file uploaded to {TARGET_BUCKET}/{clean_key}")

        return {
            'statusCode': 200,
            'body': json.dumps(f'File processed: {clean_key}')
        }

    except Exception as e:
        print(f"Error processing file: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps(f"Error: {str(e)}")
        }